# Maya Protocol Arbitrage Scanner\n\n## Project Overview\nThis project is a scanner for arbitrage opportunities on Maya Protocol. It fetches real-time transaction data, identifies potential arbitrage opportunities by comparing input and output values against market prices, and provides a web interface for monitoring. The project is being developed in multiple phases:\n\n- **Phase 1: Data Collection and Preprocessing** (COMPLETE)\n    - Fetches all actions (transactions) from Maya Protocol's Midgard API for the last 24 hours.\n    - Streams real-time confirmed and pending transactions.\n    - Groups pending transactions into a conceptual \"pending block.\"\n    - Provides a Flask web application to display historical, live confirmed, and pending transaction data.\n    - Implements an AI preprocessing pipeline to prepare data for model training.\n- **Phase 2: Model Development** (NEXT)\n    - Build and train a transformer-based model to predict arbitrage opportunities.\n- **Phase 3: Reporting and Simulation**\n    - Simulate and report on arbitrage strategies using the trained model.\n\n## Phase 1 Deliverables\n- **Historical Data:**\n    - `data/historical_24hr_maya_transactions.csv`: All Maya Protocol actions from the last 24 hours.\n- **Real-Time Streaming:**\n    - `src/realtime_stream_manager.py`: Streams confirmed and pending actions from the Midgard API.\n- **Web Application:**\n    - `src/app.py`: Flask app serving endpoints and a dashboard for historical and live data.\n    - `src/templates/index.html`, `src/static/style.css`, `src/static/script.js`: Frontend files for the dashboard.\n- **AI Preprocessing Pipeline:**\n    - `src/preprocess_ai_data.py`: Loads historical data, performs feature engineering, normalization, and sequence generation for AI model input.\n    - **Output files (in `data/processed_ai_data/`):**\n        - `sequences.npy`: 3D NumPy array of transaction sequences for model training.\n        - `sequence_transaction_ids.json`: List of transaction IDs for each sequence.\n        - `asset_to_id.json`, `type_to_id.json`, `status_to_id.json`: Mappings for categorical features.\n        - `scaler.pkl`: Fitted scaler for normalizing features.\n\n## Current Status\n- **Phase 1 is complete.** All data engineering, streaming, web, and preprocessing components are functional.\n- **Ready to begin Phase 2: Model Development.**\n\n## Getting Started\n1. Install dependencies in a virtual environment:\n    ```bash\n    python3 -m venv .venv\n    .venv/bin/pip install -r requirements.txt\n    ```\n2. Fetch historical and real-time data:\n    ```bash\n    .venv/bin/python src/fetch_realtime_transactions.py\n    ```\n3. Run the AI preprocessing pipeline:\n    ```bash\n    .venv/bin/python src/preprocess_ai_data.py\n    ```\n4. Start the Flask web app:\n    ```bash\n    .venv/bin/python src/app.py\n    ```\n\n## Next Steps\n- Implement and train the transformer-based arbitrage prediction model (Phase 2).\n- See `Docs/Implementation Plan.md` for detailed phase breakdowns.\n
